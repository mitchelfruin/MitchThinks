---
title: "A Field Guide to Lies & Stats - Levitin 2016"
date: "2019-08-10"
output:
  blogdown::html_page:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

If you want to see the full code for this post then you can find the .Rmd file [here](https://github.com/mitchelfruin/MitchThinks/blob/master/content/books/lies_and_stats_Levitin_2016.Rmd).

# Summary

Levitin provides a solid compilation of mistakes to avoid and tricks to look out for when producing and reading research respectively. However, given his background in  psychology and neuroscience, I was hoping for a more general thread pulling the examples together concerning *why* the human brain is 'fooled' by particular ways of presenting information rather than just *what* those presentations are.

The book's main strength was its illustrative examples which stuck in my mind and comprise the rest of this post.

# Is the stat plausible?

The first thing to check when presented with a statistic, especially out of context, is whether the claim is even plausible in the first place. 

## Back of the napkin calculations

One way to check plausibility is a quick on-the-fly calculation.

Say, for example, we run into someone claiming that "in the 35 years since marijuana laws stopped being enforced in California, the number of marijuana smokers has doubled every year". 

Well, even if we start with the most generous estimate that intitially there was only 1 lonely pothead in California, then if that number doubled every year for 35 years:

$$\begin{aligned}
\text{Year 1:} \;\; 1 &= 2^0 \\
\text{Year 2:} \;\; 2 &= 2^1 \\
\text{Year 3:} \;\; 4 &= 2^2 \\
\vdots \\
\text{Year 35:} \;\; &= 2^{34} \\
\end{aligned}$$

So let's see just how many marijuana smokers we've currently got if that stat holds:
```{r potheads}
# Too high to count that high
2^34
```

Just over 17.1 billion people, which seems more than a little high. 

## Remember the real world

Checking birth rates 3 months after a policy change attempting to discourage pregnancy. 200% decreases mean the person is now paying you as much as you used to pay them. 

# Does the average mean anything?

## Mean, median and mode

## Bimodal distributions

Humans on average have one testicle. Meaningless to compute an average on a metric over a whole population where there are important differences. 

# Are the axes leading you astray?

## Truncated

Exaggerate between-group differences. If 0 is a plausible value it should be included. 

## Discontinuous

Easy to make line graph jump. 

## Elongated

Include axis space beyond the range of your data to make changes look more extreme. 

## Duplicate

If they measure the same thing then you can fudge the graph however you want. Only use if they're different units and you want to make within axis comparisons not between. E.g. planned parenthood jason chaffetz. 

# Dodgy reporting 

## Hiding a decrease in the cumulative

Tim Cook iPhone sales. 

## Unrelated plotting

Spurious time series. 

## Irrelevant differences

Just increase N enough to lower the p-value until it's 'significant'.

## Comparing apples and oranges 

**Amalgamating**: group samples that differ on an important dimension to make the stat more shocking. "50% of 10-18 year olds are sexually active". 

**Subdividing**: split things inconsistently to make your point more impressive. Divide all causes of death into subcategories apart from the one you want to promote. Should be equal bins (either by percentile of absolute).  

# That's probably not quite right

## Conditional probabilities

Sometimes probability is unintuitive. Birthday puzzle. 

**Types.** Classic, based on symmetry. Frequentist, based on experience. Subjective, based on best guess. 

**Independent probabilities.** Should multiply. 

**Dependent/Conditional probabilities.** Sally Clark had two children dies from SIDs. Dr. Meadow, peadiatrician, said there's 1 in 8543 chance of having a child die from SIDs giving a 1 in 73mil chance of having two children die from it. Potential genetic, environmental dependence ignored and she was sentenced for 3 years. Visualise bayesian updating with a contingency table. Base rate neglect in medical test results. 

## The prosecutor's fallacy

**Prosecutor's fallacy:** False belief that conditional probabilities are invertible when in fact they aren't.

$$Pr(A|B) \neq Pr(B|A)$$

Forensics may compute that probability of blood at scene matching the defendent's by chance is 1%. That doesn't mean there's a 1% chance the defendent is innocent. We have been told the probability of a match given innocence, we want the probability of innocence given a match, but they don't equate:

$$Pr(\text{match}|\text{innocent}) \neq Pr(\text{innocent}|\text{match})$$

## Bayesian updating

